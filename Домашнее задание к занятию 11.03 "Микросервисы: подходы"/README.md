# Домашнее задание к занятию "Микросервисы: подходы"

Вы работаете в крупной компанию, которая строит систему на основе микросервисной архитектуры.
Вам как DevOps специалисту необходимо выдвинуть предложение по организации инфраструктуры, для разработки и эксплуатации.


## Задача 1: Обеспечить разработку

Предложите решение для обеспечения процесса разработки: хранение исходного кода, непрерывная интеграция и непрерывная поставка.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- Облачная система;
- Система контроля версий Git;
- Репозиторий на каждый сервис;
- Запуск сборки по событию из системы контроля версий;
- Запуск сборки по кнопке с указанием параметров;
- Возможность привязать настройки к каждой сборке;
- Возможность создания шаблонов для различных конфигураций сборок;
- Возможность безопасного хранения секретных данных: пароли, ключи доступа;
- Несколько конфигураций для сборки из одного репозитория;
- Кастомные шаги при сборке;
- Собственные докер образы для сборки проектов;
- Возможность развернуть агентов сборки на собственных серверах;
- Возможность параллельного запуска нескольких сборок;
- Возможность параллельного запуска тестов;

Обоснуйте свой выбор.

## Ответ:

Из решения я бы предложил следующий вариант стека:
1. Gitlab - хранение исходного кода и сборка проектов
2. k3s - среда развертывания контейнера
3. vault - централизованное хранилище секретов
4. SonarQube - контроль и тестирование кода

Gitlab предоставляет массу возможностей для команд разработки при относительно не больших трудозатратах для инженера по настройке сборок. Gitlab-runner можно установить на любом сервере. Он не привязан к серверу где развернут сам гитлаб. Предложенный стек удовлетворяет всем требованиям:
- Облачная система;
- Система контроля версий Git;
- Репозиторий на каждый сервис;
- Запуск сборки по событию из системы контроля версий;
- Запуск сборки по кнопке с указанием параметров;
- Возможность привязать настройки к каждой сборке;
- Возможность создания шаблонов для различных конфигураций сборок;
- Возможность безопасного хранения секретных данных: пароли, ключи доступа; (По этому пункту тут можно сказать что при наличии централизованного ci/cd репозитория можно установить чувствительные, для сборки, секреты в variables)
- Несколько конфигураций для сборки из одного репозитория;
- Собственные докер образы для сборки проектов; (При установке Gitlab можно так же установить docker-registry который предоставляется самим Gitlab из коробки, но требует небольших настроек)
- Возможность развернуть агентов сборки на собственных серверах;
- Возможность параллельного запуска нескольких сборок;
- Возможность параллельного запуска тестов;

Из плюсов стека можно отметить что все решения являются открытыми(бесплатными), что в свою очередь экономит деньги при старте проекта.


## Задача 2: Логи

Предложите решение для обеспечения сбора и анализа логов сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- Сбор логов в центральное хранилище со всех хостов обслуживающих систему;
- Минимальные требования к приложениям, сбор логов из stdout;
- Гарантированная доставка логов до центрального хранилища;
- Обеспечение поиска и фильтрации по записям логов;
- Обеспечение пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов;
- Возможность дать ссылку на сохраненный поиск по записям логов;

Обоснуйте свой выбор.

## Ответ:
Тут мнения могут разделяться на два фронта:
1. ELK - стек
2. GPCV(Grafana, Prometheus, Clickhouse)

Я бы сделал выбор в пользу второго так как фактически в дальнейшем к нему привязать можно и мониторинг. Но на мой взгляд это подойдет для относительно не большого проекта т.к. при большом потоке логов есть вероятность, что параллельный сбор логов и метрик на 1 совместный сервер сбора логов и метрик будет заметно тормозить производительность
На самом деле тут уже играют вкусовые предпочтения. Но что бы не разрастать стек предлагаю для не большой команды и проекта использовать Grafana и Clickhouse. Clickhouse можно заменить на loki однако потребуется отдельный сервер 

## Задача 3: Мониторинг

Предложите решение для обеспечения сбора и анализа состояния хостов и сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- Сбор метрик со всех хостов, обслуживающих систему;
- Сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network;
- Сбор метрик потребляемых ресурсов для каждого сервиса: CPU, RAM, HDD, Network;
- Сбор метрик, специфичных для каждого сервиса;
- Пользовательский интерфейс с возможностью делать запросы и агрегировать информацию;
- Пользовательский интерфейс с возможность настраивать различные панели для отслеживания состояния системы;

Обоснуйте свой выбор.

## Ответ:
Тут я бы однозначно предложил стек с Grafana, Prometheus. Prometheus может быть развернут на каждом инстансе где требуется собрать метрики. Требуется только направить эти метрики в централизованный инстанс Grafana. Grafana предоставляет возможность гибко и под себя/отдельный сервис настроить дашборды с использованием присланных метрик. Так же в запросе можно писать функции которые сырые данные от Prometheus будет преобразовывать в проценты или любой иной читаемый вид.
Для старта Grafana предоставляет репозиторий с готовыми дашбордами которые может использовать любой, кто решил использовать Grafana.

## Задача 4: Логи * (необязательная)

Продолжить работу по задаче API Gateway: сервисы используемые в задаче пишут логи в stdout.

Добавить в систему сервисы для сбора логов Vector + ElasticSearch + Kibana со всех сервисов обеспечивающих работу API.

### Результат выполнения:

docker compose файл запустив который можно перейти по адресу http://localhost:8081 по которому доступна Kibana.
Логин в Kibana должен быть admin пароль qwerty123456


## Задача 5: Мониторинг * (необязательная)

Продолжить работу по задаче API Gateway: сервисы используемые в задаче предоставляют набор метрик в формате prometheus:

- Сервис security по адресу /metrics
- Сервис uploader по адресу /metrics
- Сервис storage (minio) по адресу /minio/v2/metrics/cluster

Добавить в систему сервисы для сбора метрик (Prometheus и Grafana) со всех сервисов обеспечивающих работу API.
Построить в Graphana dashboard показывающий распределение запросов по сервисам.

### Результат выполнения:

docker compose файл запустив который можно перейти по адресу http://localhost:8081 по которому доступна Grafana с настроенным Dashboard.
Логин в Grafana должен быть admin пароль qwerty123456

---

### Как оформить ДЗ?

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.

---